{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM5894wZbvQ0"
   },
   "source": [
    "# Training an Image Recognition Model\n",
    "\n",
    "The final section of this tutorial is more useful when targeting specific image recognition tasks that can't be dont using pretrained models, as these objects may not have been included in those models, and thus will not be recognized. In this tutorial, we will train a classification model to recognize handwritten numerical digits 0-9. Classification of handwritten symbols can be generalized to be used to document written texts, improve human computer interface efficiency, etc.\n",
    "\n",
    "The training dataset *digits* includes 1000 training images, as well as 200 validation images, per image. There are also two small folders of test digits, *test-data*, which includes separate images taken from the same dataset, and *test-data2*, which contains images downloaded from Google search. \n",
    "\n",
    "First, import the required training library from imageai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOWoHkgYEd-e"
   },
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import ModelTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_R6aErse7Ue"
   },
   "source": [
    "Here, a trainer object, *model_trainer*, is initialized. We swill use the InceptionV3 model here, with the training data directory set to *digits*. Wehn executing the *trainModel* function, *num_objects* is set to 10 since there are 10 digit objects in our data, and we will run *num_experiments*=15 times to find the best model (more runs mean a more accurate model, with diminishing return). Finally, *set_network_summary* is true, to display the following outputs of training. \n",
    "\n",
    "**This training was run on a Google cloud server using an Nvidia K80 GPU and tensorflow GPU. Total training time was 2 hours. Training on a local machine may take several hours or days.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0sArNxHgUMfz",
    "outputId": "b5042d3a-84f0-4646-c62c-ca48f9135f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 111, 111, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_376 (Bat (None, 111, 111, 32) 96          conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 111, 111, 32) 0           batch_normalization_v1_376[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 109, 109, 32) 9216        activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_377 (Bat (None, 109, 109, 32) 96          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 109, 109, 32) 0           batch_normalization_v1_377[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 109, 109, 64) 18432       activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_378 (Bat (None, 109, 109, 64) 192         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 109, 109, 64) 0           batch_normalization_v1_378[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 54, 54, 64)   0           activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_379 (Bat (None, 54, 54, 80)   240         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 54, 54, 80)   0           batch_normalization_v1_379[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 52, 52, 192)  138240      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_380 (Bat (None, 52, 52, 192)  576         conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 52, 52, 192)  0           batch_normalization_v1_380[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 25, 25, 192)  0           activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_384 (Bat (None, 25, 25, 64)   192         conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_384[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 25, 25, 96)   55296       activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_382 (Bat (None, 25, 25, 48)   144         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_385 (Bat (None, 25, 25, 96)   288         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_382[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_385[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 25, 25, 64)   76800       activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 25, 25, 96)   82944       activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_381 (Bat (None, 25, 25, 64)   192         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_383 (Bat (None, 25, 25, 64)   192         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_386 (Bat (None, 25, 25, 96)   288         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_387 (Bat (None, 25, 25, 32)   96          conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_381[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_383[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_386[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 25, 25, 32)   0           batch_normalization_v1_387[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_381[0][0]             \n",
      "                                                                 activation_383[0][0]             \n",
      "                                                                 activation_386[0][0]             \n",
      "                                                                 activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_391 (Bat (None, 25, 25, 64)   192         conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_391[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 25, 25, 96)   55296       activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_389 (Bat (None, 25, 25, 48)   144         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_392 (Bat (None, 25, 25, 96)   288         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_389[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_392[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_37 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 25, 25, 64)   76800       activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 25, 25, 96)   82944       activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_388 (Bat (None, 25, 25, 64)   192         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_390 (Bat (None, 25, 25, 64)   192         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_393 (Bat (None, 25, 25, 96)   288         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_394 (Bat (None, 25, 25, 64)   192         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_388[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_390[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_393[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_394[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_388[0][0]             \n",
      "                                                                 activation_390[0][0]             \n",
      "                                                                 activation_393[0][0]             \n",
      "                                                                 activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_398 (Bat (None, 25, 25, 64)   192         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_398[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 25, 25, 96)   55296       activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_396 (Bat (None, 25, 25, 48)   144         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_399 (Bat (None, 25, 25, 96)   288         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_396[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_399[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_38 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 25, 25, 64)   76800       activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 25, 25, 96)   82944       activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_395 (Bat (None, 25, 25, 64)   192         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_397 (Bat (None, 25, 25, 64)   192         conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_400 (Bat (None, 25, 25, 96)   288         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_401 (Bat (None, 25, 25, 64)   192         conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_395[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_397[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_400[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_401[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_395[0][0]             \n",
      "                                                                 activation_397[0][0]             \n",
      "                                                                 activation_400[0][0]             \n",
      "                                                                 activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_403 (Bat (None, 25, 25, 64)   192         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_403[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 25, 25, 96)   55296       activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_404 (Bat (None, 25, 25, 96)   288         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_404[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 12, 12, 96)   82944       activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_402 (Bat (None, 12, 12, 384)  1152        conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_405 (Bat (None, 12, 12, 96)   288         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 12, 12, 384)  0           batch_normalization_v1_402[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 12, 12, 96)   0           batch_normalization_v1_405[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_402[0][0]             \n",
      "                                                                 activation_405[0][0]             \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_410 (Bat (None, 12, 12, 128)  384         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_410[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 12, 12, 128)  114688      activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_411 (Bat (None, 12, 12, 128)  384         conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_411[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 12, 12, 128)  114688      activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_407 (Bat (None, 12, 12, 128)  384         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_412 (Bat (None, 12, 12, 128)  384         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_407[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_412[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 12, 12, 128)  114688      activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 12, 12, 128)  114688      activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_408 (Bat (None, 12, 12, 128)  384         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_413 (Bat (None, 12, 12, 128)  384         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_408[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_413[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_39 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 12, 12, 192)  172032      activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 12, 12, 192)  172032      activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_406 (Bat (None, 12, 12, 192)  576         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_409 (Bat (None, 12, 12, 192)  576         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_414 (Bat (None, 12, 12, 192)  576         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_415 (Bat (None, 12, 12, 192)  576         conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_406[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_409[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_414[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_415[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_406[0][0]             \n",
      "                                                                 activation_409[0][0]             \n",
      "                                                                 activation_414[0][0]             \n",
      "                                                                 activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_420 (Bat (None, 12, 12, 160)  480         conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_420[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 12, 12, 160)  179200      activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_421 (Bat (None, 12, 12, 160)  480         conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_421[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 12, 12, 160)  179200      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_417 (Bat (None, 12, 12, 160)  480         conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_422 (Bat (None, 12, 12, 160)  480         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_417[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_422[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 12, 12, 160)  179200      activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 12, 12, 160)  179200      activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_418 (Bat (None, 12, 12, 160)  480         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_423 (Bat (None, 12, 12, 160)  480         conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_418[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_423[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_40 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 12, 12, 192)  215040      activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 12, 12, 192)  215040      activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_416 (Bat (None, 12, 12, 192)  576         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_419 (Bat (None, 12, 12, 192)  576         conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_424 (Bat (None, 12, 12, 192)  576         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_425 (Bat (None, 12, 12, 192)  576         conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_416[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_419[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_424[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_425[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_416[0][0]             \n",
      "                                                                 activation_419[0][0]             \n",
      "                                                                 activation_424[0][0]             \n",
      "                                                                 activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_430 (Bat (None, 12, 12, 160)  480         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_430[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 12, 12, 160)  179200      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_431 (Bat (None, 12, 12, 160)  480         conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_431[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 12, 12, 160)  179200      activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_427 (Bat (None, 12, 12, 160)  480         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_432 (Bat (None, 12, 12, 160)  480         conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_427[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_432[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 12, 12, 160)  179200      activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 12, 12, 160)  179200      activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_428 (Bat (None, 12, 12, 160)  480         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_433 (Bat (None, 12, 12, 160)  480         conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_428[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_433[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_41 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 12, 12, 192)  215040      activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 12, 12, 192)  215040      activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_426 (Bat (None, 12, 12, 192)  576         conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_429 (Bat (None, 12, 12, 192)  576         conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_434 (Bat (None, 12, 12, 192)  576         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_435 (Bat (None, 12, 12, 192)  576         conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_426[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_429[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_434[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_435[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_426[0][0]             \n",
      "                                                                 activation_429[0][0]             \n",
      "                                                                 activation_434[0][0]             \n",
      "                                                                 activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_440 (Bat (None, 12, 12, 192)  576         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_440[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 12, 12, 192)  258048      activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_441 (Bat (None, 12, 12, 192)  576         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_441[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 12, 12, 192)  258048      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_437 (Bat (None, 12, 12, 192)  576         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_442 (Bat (None, 12, 12, 192)  576         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_437[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_442[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 12, 12, 192)  258048      activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 12, 12, 192)  258048      activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_438 (Bat (None, 12, 12, 192)  576         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_443 (Bat (None, 12, 12, 192)  576         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_438[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_443[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_42 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 12, 12, 192)  258048      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 12, 12, 192)  258048      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_436 (Bat (None, 12, 12, 192)  576         conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_439 (Bat (None, 12, 12, 192)  576         conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_444 (Bat (None, 12, 12, 192)  576         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_445 (Bat (None, 12, 12, 192)  576         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_436[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_439[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_444[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_445[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_436[0][0]             \n",
      "                                                                 activation_439[0][0]             \n",
      "                                                                 activation_444[0][0]             \n",
      "                                                                 activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_448 (Bat (None, 12, 12, 192)  576         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_448[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 12, 12, 192)  258048      activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_449 (Bat (None, 12, 12, 192)  576         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_449[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 12, 12, 192)  258048      activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_446 (Bat (None, 12, 12, 192)  576         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_450 (Bat (None, 12, 12, 192)  576         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_446[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_450[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 5, 5, 320)    552960      activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 5, 5, 192)    331776      activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_447 (Bat (None, 5, 5, 320)    960         conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_451 (Bat (None, 5, 5, 192)    576         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_447[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_451[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_447[0][0]             \n",
      "                                                                 activation_451[0][0]             \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_456 (Bat (None, 5, 5, 448)    1344        conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 5, 5, 448)    0           batch_normalization_v1_456[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 5, 5, 384)    1548288     activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_453 (Bat (None, 5, 5, 384)    1152        conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_457 (Bat (None, 5, 5, 384)    1152        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_453[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_457[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_43 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_454 (Bat (None, 5, 5, 384)    1152        conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_455 (Bat (None, 5, 5, 384)    1152        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_458 (Bat (None, 5, 5, 384)    1152        conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_459 (Bat (None, 5, 5, 384)    1152        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_43[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_452 (Bat (None, 5, 5, 320)    960         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_454[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_455[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_458[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_459[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_460 (Bat (None, 5, 5, 192)    576         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_452[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_454[0][0]             \n",
      "                                                                 activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_458[0][0]             \n",
      "                                                                 activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_460[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_452[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_465 (Bat (None, 5, 5, 448)    1344        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 5, 5, 448)    0           batch_normalization_v1_465[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 5, 5, 384)    1548288     activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_462 (Bat (None, 5, 5, 384)    1152        conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_466 (Bat (None, 5, 5, 384)    1152        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_462[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_466[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_463 (Bat (None, 5, 5, 384)    1152        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_464 (Bat (None, 5, 5, 384)    1152        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_467 (Bat (None, 5, 5, 384)    1152        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_468 (Bat (None, 5, 5, 384)    1152        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_461 (Bat (None, 5, 5, 320)    960         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_463[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_464[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_467[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_468[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_469 (Bat (None, 5, 5, 192)    576         conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_461[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_463[0][0]             \n",
      "                                                                 activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 5, 5, 768)    0           activation_467[0][0]             \n",
      "                                                                 activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_469[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_461[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 activation_469[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           20490       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,823,274\n",
      "Trainable params: 21,788,842\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "Found 10736 images belonging to 10 classes.\n",
      "Found 2251 images belonging to 10 classes.\n",
      "JSON Mapping for the model classes saved to  digits/json/model_class.json\n",
      "Number of experiments (Epochs) :  15\n",
      "Epoch 1/15\n",
      "71/71 [==============================] - 15s 215ms/step - loss: 14.4387 - acc: 0.1026\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.10262, saving model to digits/models/model_ex-001_acc-0.102621.h5\n",
      "336/336 [==============================] - 451s 1s/step - loss: 0.2799 - acc: 0.9186 - val_loss: 14.4387 - val_acc: 0.1026\n",
      "Epoch 2/15\n",
      "71/71 [==============================] - 13s 186ms/step - loss: 0.0810 - acc: 0.9787\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.10262 to 0.97868, saving model to digits/models/model_ex-002_acc-0.978676.h5\n",
      "336/336 [==============================] - 246s 731ms/step - loss: 0.1313 - acc: 0.9597 - val_loss: 0.0810 - val_acc: 0.9787\n",
      "Epoch 3/15\n",
      "71/71 [==============================] - 13s 186ms/step - loss: 0.1070 - acc: 0.9640\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97868\n",
      "336/336 [==============================] - 244s 727ms/step - loss: 0.0787 - acc: 0.9784 - val_loss: 0.1070 - val_acc: 0.9640\n",
      "Epoch 4/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.1144 - acc: 0.9622\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97868\n",
      "336/336 [==============================] - 244s 726ms/step - loss: 0.0642 - acc: 0.9799 - val_loss: 0.1144 - val_acc: 0.9622\n",
      "Epoch 5/15\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 0.0535 - acc: 0.9867\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97868 to 0.98667, saving model to digits/models/model_ex-005_acc-0.986673.h5\n",
      "336/336 [==============================] - 245s 730ms/step - loss: 0.0673 - acc: 0.9808 - val_loss: 0.0535 - val_acc: 0.9867\n",
      "Epoch 6/15\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 0.0570 - acc: 0.9831\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.98667\n",
      "336/336 [==============================] - 244s 727ms/step - loss: 0.0442 - acc: 0.9854 - val_loss: 0.0570 - val_acc: 0.9831\n",
      "Epoch 7/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.3630 - acc: 0.9103\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.98667\n",
      "336/336 [==============================] - 244s 726ms/step - loss: 0.0447 - acc: 0.9862 - val_loss: 0.3630 - val_acc: 0.9103\n",
      "Epoch 8/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.0053 - acc: 0.9987\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.98667 to 0.99867, saving model to digits/models/model_ex-008_acc-0.998667.h5\n",
      "336/336 [==============================] - 245s 729ms/step - loss: 0.0241 - acc: 0.9920 - val_loss: 0.0053 - val_acc: 0.9987\n",
      "Epoch 9/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.0033 - acc: 0.9991\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.99867 to 0.99911, saving model to digits/models/model_ex-009_acc-0.999112.h5\n",
      "336/336 [==============================] - 245s 729ms/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 0.9991\n",
      "Epoch 10/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.0024 - acc: 0.9996\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99911 to 0.99956, saving model to digits/models/model_ex-010_acc-0.999556.h5\n",
      "336/336 [==============================] - 245s 729ms/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0024 - val_acc: 0.9996\n",
      "Epoch 11/15\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 0.0026 - acc: 0.9996\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99956\n",
      "336/336 [==============================] - 245s 728ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0026 - val_acc: 0.9996\n",
      "Epoch 12/15\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 0.0016 - acc: 0.9996\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99956\n",
      "336/336 [==============================] - 245s 728ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0016 - val_acc: 0.9996\n",
      "Epoch 13/15\n",
      "71/71 [==============================] - 13s 188ms/step - loss: 0.0016 - acc: 0.9996\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99956\n",
      "336/336 [==============================] - 245s 730ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0016 - val_acc: 0.9996\n",
      "Epoch 14/15\n",
      "71/71 [==============================] - 13s 187ms/step - loss: 0.0015 - acc: 0.9996\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99956\n",
      "336/336 [==============================] - 245s 729ms/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0015 - val_acc: 0.9996\n",
      "Epoch 15/15\n",
      "71/71 [==============================] - 14s 191ms/step - loss: 0.0015 - acc: 0.9996\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99956\n",
      "336/336 [==============================] - 245s 731ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0015 - val_acc: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# define model trainer and train data\n",
    "model_trainer = ModelTraining()\n",
    "model_trainer.setModelTypeAsInceptionV3()\n",
    "model_trainer.setDataDirectory('digits')\n",
    "model_trainer.trainModel(num_objects=10, num_experiments=15, show_network_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jlcErYmKgVyz"
   },
   "source": [
    "As we see in the output, models improved from epoch 1-11, wth no improvements from 12-15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzKr61PmgB77"
   },
   "source": [
    "# Predicting using custom model\n",
    "\n",
    "Now, we will use the model we generated to predict a few handwritten images.\n",
    "\n",
    "Import the custom prediction library from imageai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6xNqEm5Ixv_"
   },
   "outputs": [],
   "source": [
    "from imageai.Prediction.Custom import CustomImagePrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlXJ-DpRhNIl"
   },
   "source": [
    "Load in the model, similar to loading in pretrained models (except now the models were generated from our data). For custom models, we pass in the number of objects we trained on, 10. We are still using InceptionV3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUcKp9uHI0UI"
   },
   "outputs": [],
   "source": [
    "# load custom prediction model\n",
    "prediction = CustomImagePrediction()\n",
    "prediction.setModelTypeAsInceptionV3()\n",
    "prediction.setModelPath('digits/models/model_ex-010_acc-0.999556.h5')\n",
    "prediction.setJsonPath('digits/json/model_class.json')\n",
    "prediction.loadModel(num_objects=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KekwFfm1hnA6"
   },
   "source": [
    "Load the test image files from *test-data* to the *images* array.\n",
    "\n",
    "We are using [Pillow](https://pillow.readthedocs.io/en/stable/) and [Ipython](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html) to print the images to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "UJ_wwsb6M15Q",
    "outputId": "13e6a32a-0f35-46ed-e7f0-72ccf7e62a3e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAANZklEQVR4nO1a2XIcx3I9mVXdPfuC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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x7EFFB3D0CE80>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAPkklEQVR4nK1a2XIjx5U952YWdoAE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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x7EFFB3D0CE80>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAPV0lEQVR4nJVaWVsbSbI9EVmlfQFJ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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x7EFFB3D0CE80>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAAAAABVicqIAAAQCElEQVR4nJVaWXMbR5L+Mqv6AIiL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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=100x100 at 0x7EFFB3D0CE80>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# load image files into array and print images from test-data\n",
    "images = []\n",
    "all_files = os.listdir('test-data')\n",
    "for file in all_files:\n",
    "  img = Image.open(os.path.join('test-data', file))\n",
    "  img = img.resize((100, 100), Image.ANTIALIAS)\n",
    "  display(img)\n",
    "  images.append(os.path.join('test-data', file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvDeTiGbidek"
   },
   "source": [
    "Run the prediction function for multiple images on our test data. Here, we specify using *result_count_per_image* that we want the first three predictions from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "7N2OuTrLUYtz",
    "outputId": "4864d9be-fb87-4ec5-9568-5fd40f690b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  :  99.99570846557617\n",
      "5  :  0.0042626717913663015\n",
      "0  :  1.5900423022685573e-05\n",
      "-----------------------\n",
      "4  :  99.99792575836182\n",
      "9  :  0.001527062886452768\n",
      "7  :  0.00024588025553384796\n",
      "-----------------------\n",
      "8  :  99.99994039535522\n",
      "3  :  3.2032900776357565e-05\n",
      "6  :  1.8815445912423456e-05\n",
      "-----------------------\n",
      "3  :  99.99990463256836\n",
      "8  :  4.573344938307855e-05\n",
      "2  :  4.0808470203046454e-05\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# run multiple image prediction on test-data\n",
    "predictions = prediction.predictMultipleImages(images, result_count_per_image=3)\n",
    "\n",
    "# print resuts for all images\n",
    "for result in predictions:\n",
    "  pred, probability = result[\"predictions\"], result[\"percentage_probabilities\"]\n",
    "  for index in range(len(pred)):\n",
    "    print(pred[index] , \" : \" , probability[index])\n",
    "  print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlsNyuLHi1ae"
   },
   "source": [
    "Not bad! Our custom prediction model predicted each of the handwritten digit images. In the last two predictions, it is interesting to note the similarity between 3 and 8 as both were the top two predictions in each image.\n",
    "\n",
    "We proceed to run the model on *test-data2* in the same way (although here we have to preprocess the data a little to fit the color scheme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "eDQm2Fq9ZJ1i",
    "outputId": "79ff6ce9-e448-4a4a-eec8-ac1285baae5a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAABkCAIAAADrOV6nAAAJyklEQVR4nO3cSUwT3wMH8DfzptOZ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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x100 at 0x7EFFA94E0DD8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAABkCAIAAADrOV6nAAAHIElEQVR4nO3cX0hTbRwH8Oc5Z5ud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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x100 at 0x7EFFA94E07B8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAABkCAIAAADrOV6nAAASAElEQVR4nO1de4xUVZr/vnPOvfXs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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x100 at 0x7EFFA94E0DD8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL.ImageOps \n",
    "\n",
    "# load image files into array and print images from test-data2\n",
    "images2 = []\n",
    "all_files2 = os.listdir('test-data2')\n",
    "for file in all_files2:\n",
    "  if(file.endswith(\".jpg\") or file.endswith(\".jpeg\")):\n",
    "    img = Image.open(os.path.join('test-data2', file))\n",
    "    img = img.resize((150, 100), Image.ANTIALIAS)\n",
    "    img = PIL.ImageOps.invert(img)\n",
    "    display(img)\n",
    "    img.save(os.path.join('test-data2-new', file))\n",
    "    images2.append(os.path.join('test-data2-new', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "XBkgvIhDZBqf",
    "outputId": "b955963f-960d-4995-8c73-a5676dc7595f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  :  97.55802750587463\n",
      "1  :  1.0391892865300179\n",
      "8  :  0.6439631339162588\n",
      "-----------------------\n",
      "1  :  96.87443375587463\n",
      "2  :  1.4837860129773617\n",
      "9  :  0.6688527762889862\n",
      "-----------------------\n",
      "4  :  99.62502121925354\n",
      "7  :  0.3557921387255192\n",
      "1  :  0.009620194759918377\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# run multiple image prediction on test-data2\n",
    "predictions2 = prediction.predictMultipleImages(images2, result_count_per_image=3)\n",
    "\n",
    "# print resuts for all images\n",
    "for result in predictions2:\n",
    "  pred2, probability2 = result[\"predictions\"], result[\"percentage_probabilities\"]\n",
    "  for index in range(len(pred2)):\n",
    "    print(pred2[index] , \" : \" , probability2[index])\n",
    "  print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLMUvjgSjdMj"
   },
   "source": [
    "Our second data set also had pretty good predictions for the first and last image, but it did classify the second image incorrectly as a 1. We note that although we had good results, the amount of data and the training we did may not be enough to ensure maximum accuracy. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "image-classification-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
